# ‚òÅÔ∏è Cloud Logging

## üìë √çndice

* [üß≠ Descripci√≥n](#-descripci√≥n)
* [üìò Detalles](#-detalles)
* [üî¨ Laboratorio Pr√°ctico (CLI-TDD)](#-laboratorio-pr√°ctico-cli-tdd)
* [üí° Lecciones Aprendidas](#-lecciones-aprendidas)
* [‚ö†Ô∏è Errores y Confusiones Comunes](#Ô∏è-errores-y-confusiones-comunes)
* [üéØ Tips de Examen](#-tips-de-examen)
* [üßæ Resumen](#-resumen)
* [‚úçÔ∏è Firma](#-firma)

---

## üß≠ Descripci√≥n

Cloud Logging es un servicio de gesti√≥n de registros (logs) totalmente gestionado y en tiempo real. Su prop√≥sito es proporcionar un lugar centralizado para el almacenamiento, la b√∫squeda, el an√°lisis y la creaci√≥n de alertas sobre datos de logs procedentes de servicios de Google Cloud, aplicaciones personalizadas, sistemas on-premises e incluso otras nubes.

Resuelve el desaf√≠o cr√≠tico de la gesti√≥n de logs a escala, permiti√©ndote realizar un troubleshooting eficaz de aplicaciones e infraestructura, llevar a cabo an√°lisis de seguridad, y mantener el cumplimiento de normativas al ofrecer un √∫nico punto de verdad para todos tus registros.

---

## üìò Detalles

Cloud Logging es m√°s que un simple visor de logs. Es un sistema completo con varios componentes que trabajan en conjunto.

### üîπ Log Router y Sinks (Receptores)

El **Log Router** es el coraz√≥n de Logging. Act√∫a como un concentrador central que procesa todos los logs que llegan a tu proyecto o organizaci√≥n. Bas√°ndose en reglas que t√∫ defines, el Log Router reenv√≠a los logs a diferentes destinos a trav√©s de **Sinks** (receptores).

Un Sink es una regla que define dos cosas:
1.  **Filtro:** Qu√© logs se van a enrutar (ej. `severity=ERROR` o `resource.type="gce_instance"`). Se pueden crear filtros de inclusi√≥n (solo estos) y de exclusi√≥n (todos menos estos).
2.  **Destino:** A d√≥nde se enviar√°n los logs filtrados. Los destinos principales son:
    *   **Cloud Storage:** Para archivado a largo plazo y bajo costo (cold storage).
    *   **BigQuery:** Para an√°lisis complejos y a gran escala (analytics).
    *   **Pub/Sub:** Para integrar los logs con otros sistemas o flujos de trabajo en tiempo real (streaming).
    *   **Otro Bucket de Logging:** Para centralizar logs de varios proyectos en un √∫nico bucket.

### üîπ Log Buckets y Vistas

Los **Log Buckets** son los contenedores donde se almacenan los logs dentro de Cloud Logging. Permiten configurar la retenci√≥n de datos y el control de acceso. Existen tres tipos:
*   `_Required`: Un bucket especial que siempre existe y almacena los logs de auditor√≠a. No se puede modificar ni eliminar.
*   `_Default`: El bucket por defecto donde se env√≠an la mayor√≠a de los logs si no se especifica otra cosa. Su retenci√≥n por defecto es de 30 d√≠as.
*   **Buckets definidos por el usuario:** Puedes crear tus propios buckets con pol√≠ticas de retenci√≥n personalizadas (de 1 d√≠a a 10 a√±os).

Las **Vistas de Logs (Log Views)** permiten un control de acceso a√∫n m√°s fino, dando a los usuarios acceso solo a un subconjunto de los logs dentro de un bucket.

### üîπ Explorador de Registros (Log Explorer)

Es la interfaz gr√°fica principal para interactuar con tus logs. Permite buscar, visualizar y analizar logs en tiempo real utilizando el **Lenguaje de Consultas de Logging (Logging Query Language)**, una sintaxis potente para filtrar por recurso, severidad, contenido del payload, y mucho m√°s.

### üîπ M√©tricas y Alertas Basadas en Logs

Cloud Logging se integra a la perfecci√≥n con Cloud Monitoring. Puedes crear:
*   **M√©tricas basadas en Logs:** Convierten la informaci√≥n de los logs en m√©tricas num√©ricas. Por ejemplo, puedes contar el n√∫mero de veces que aparece un error espec√≠fico en tus logs y visualizarlo en un dashboard de Monitoring.
*   **Alertas basadas en Logs:** Crean pol√≠ticas de alerta que se disparan cuando aparece un patr√≥n de log espec√≠fico, sin necesidad de crear una m√©trica intermedia. Son ideales para eventos que son importantes pero poco frecuentes (ej. un log de seguridad cr√≠tico).

### üîπ El Agente de Operaciones (Ops Agent)

Para VMs (en GCP o on-premise), el **Ops Agent** es el agente unificado y recomendado por Google. Combina la recolecci√≥n de logs (usando Fluent Bit) y m√©tricas (usando OpenTelemetry) en un √∫nico agente, simplificando la instalaci√≥n y configuraci√≥n en comparaci√≥n con los agentes heredados (Logging Agent y Monitoring Agent).

---

## üî¨ Laboratorio Pr√°ctico (CLI-TDD)

**Escenario:** Escribiremos un log estructurado personalizado desde nuestra terminal. Crearemos un Sink para filtrar solo esos logs y enviarlos a un bucket de Cloud Storage para su archivado. Finalmente, crearemos una m√©trica basada en logs para contarlos.

### ARRANGE (Preparaci√≥n)

```bash
# Variables del proyecto y configuraci√≥n
export PROJECT_ID=$(gcloud config get-value project)
export REGION="europe-west1"
export BUCKET_NAME="log-archive-bucket-$PROJECT_ID"
export SINK_NAME="custom-log-sink"
export LOG_NAME="my-custom-log"

# Habilitar APIs necesarias
echo "Habilitando APIs de Logging, Storage y Monitoring..."
gcloud services enable logging.googleapis.com storage.googleapis.com monitoring.googleapis.com

# Crear bucket de Cloud Storage para el archivado
echo "Creando bucket de Cloud Storage..."
gsutil mb -l $REGION gs://$BUCKET_NAME

# Obtener la cuenta de servicio del sink (se crea autom√°ticamente)
# El sink writer identity se crea despu√©s de crear el sink, por lo que este paso es posterior.
```

### ACT (Implementaci√≥n)

```bash
# 1. Escribir un log estructurado (JSON) personalizado
echo "Escribiendo log estructurado..."
gcloud logging write $LOG_NAME '{"message": "Inicio de proceso batch", "status": "SUCCESS", "batch_id": "12345"}' --payload-type=json --severity=INFO

# 2. Crear un Sink para enrutar los logs personalizados a Cloud Storage
echo "Creando sink..."
gcloud logging sinks create $SINK_NAME storage.googleapis.com/$BUCKET_NAME \
    --log-filter="logName=projects/$PROJECT_ID/logs/$LOG_NAME AND jsonPayload.status='SUCCESS'"

# 3. Otorgar permisos a la cuenta de servicio del Sink sobre el bucket
# Obtenemos la identidad del escritor del sink
export SINK_WRITER_IDENTITY=$(gcloud logging sinks describe $SINK_NAME --format='value(writerIdentity)')
echo "Otorgando permisos a $SINK_WRITER_IDENTITY..."
gsutil iam ch $SINK_WRITER_IDENTITY:objectCreator gs://$BUCKET_NAME

# 4. Crear una m√©trica basada en logs para contar los logs de √©xito
echo "Creando m√©trica basada en logs..."
gcloud logging metrics create batch-success-metric \
    --description="Cuenta los procesos batch exitosos" \
    --filter="logName=projects/$PROJECT_ID/logs/$LOG_NAME AND jsonPayload.status='SUCCESS'"
```

### ASSERT (Verificaci√≥n)

```bash
# Verificar la creaci√≥n del Sink
echo "=== VERIFICANDO SINK ==="
gcloud logging sinks describe $SINK_NAME

# Verificar la creaci√≥n de la m√©trica
echo "=== VERIFICANDO M√âTRICA ==="
gcloud logging metrics describe batch-success-metric

# Escribir otro log para probar el sink y la m√©trica
echo "Escribiendo otro log para generar datos..."
gcloud logging write $LOG_NAME '{"message": "Fin de proceso batch", "status": "SUCCESS", "batch_id": "12346"}' --payload-type=json --severity=INFO

# La verificaci√≥n final requiere esperar unos minutos a que el log sea procesado y exportado.
# Despu√©s de unos 5 minutos, puedes verificar el bucket:
# gsutil ls gs://$BUCKET_NAME
```

### CLEANUP (Limpieza)

```bash
echo "‚ö†Ô∏è  Eliminando recursos de laboratorio..."
gcloud logging metrics delete batch-success-metric --quiet
gcloud logging sinks delete $SINK_NAME --quiet
gsutil rm -r gs://$BUCKET_NAME

echo "‚úÖ Laboratorio completado - Recursos eliminados"
```

---

## üí° Lecciones Aprendidas

*   **Los logs son m√°s que texto para debug:** Son una fuente de datos muy rica. Al enviarlos a BigQuery, puedes realizar an√°lisis de negocio, y al enviarlos a Pub/Sub, puedes disparar flujos de trabajo automatizados.
*   **El logging estructurado (JSON) es tu mejor aliado:** Permite realizar consultas y filtros incre√≠blemente potentes y precisos sobre los campos del log, algo imposible con texto plano.
*   **Los Sinks son la clave para la gesti√≥n de logs a escala:** Permiten implementar estrategias de almacenamiento por niveles (ej. "hot" en Logging, "warm/cold" en GCS) y segregar logs por motivos de seguridad o cumplimiento.

---

## ‚ö†Ô∏è Errores y Confusiones Comunes

*   **Permisos del Sink:** El error m√°s com√∫n es olvidar dar permisos a la cuenta de servicio del Sink (`writerIdentity`) sobre el destino. El sink se crea, pero los logs nunca llegan. La consola de GCP suele avisar de esto.
*   **Filtros incorrectos:** Escribir un filtro para un sink o en el Log Explorer que no captura los logs esperados. Es importante probar los filtros en el Log Explorer antes de aplicarlos a un sink.
*   **Desconocer la retenci√≥n por defecto:** Asumir que los logs se guardan para siempre. El bucket `_Default` tiene una retenci√≥n de 30 d√≠as. Si necesitas m√°s tiempo, debes crear un sink a GCS/BigQuery o configurar un bucket personalizado.

---

## üéØ Tips de Examen

*   Conoce los 4 destinos principales de un Sink: **Cloud Storage**, **BigQuery**, **Pub/Sub** y **otro Bucket de Logging**.
*   Entiende la funci√≥n del **Log Router**: es el componente central que recibe todos los logs y los dirige seg√∫n las reglas de los sinks.
*   Diferencia el bucket `_Required` (logs de auditor√≠a, inmutable) del bucket `_Default` (logs generales, retenci√≥n de 30 d√≠as).
*   Recuerda que el **Ops Agent** es el agente unificado y recomendado para recolectar tanto logs como m√©tricas de las VMs.

---

## üßæ Resumen

Cloud Logging ofrece una soluci√≥n centralizada, escalable y en tiempo real para la gesti√≥n de todos tus registros. A trav√©s de su potente lenguaje de consulta, sus capacidades de enrutamiento con Sinks y su profunda integraci√≥n con el resto de la suite de operaciones, constituye la base para un troubleshooting efectivo, an√°lisis de seguridad e inteligencia operacional en GCP.

---

## ‚úçÔ∏è Firma

**Marco - DevSecOps Kulture**  
*The Artisan Path*  
üìß Contacto: [markitos.es.info@gmail.com](mailto:markitos.es.info@gmail.com)  
üêô GitHub: [https://github.com/markitos-public](https://github.com/markitos-public)

---

[‚¨ÜÔ∏è **Volver arriba**](#-cloud-logging)
